import os
import json
import requests
import urllib.parse
import pandas as pd
import gspread
from io import BytesIO
from datetime import datetime
from functools import reduce
from gspread_dataframe import get_as_dataframe
from dotenv import load_dotenv
from supabase import create_client, Client

# 1. í™˜ê²½ë³€ìˆ˜ ë° Supabase ì—°ê²° ì„¤ì •
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("âŒ .env íŒŒì¼ì— Supabase ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# -----------------------------------------------------------
# [Step 1] êµ¬ê¸€ ì‹œíŠ¸ -> Supabase ë§¤í•‘ í…Œì´ë¸” ë™ê¸°í™” (ì „ì²´ ë™ê¸°í™”)
# -----------------------------------------------------------
def sync_region_mapping():
    print("\n[Step 1] êµ¬ê¸€ ì‹œíŠ¸ ë§¤í•‘ í…Œì´ë¸” ë™ê¸°í™” ì¤‘...")
    
    if not os.path.exists('credentials.json'):
        print("âŒ 'credentials.json' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë§¤í•‘ ë™ê¸°í™” ì‹¤íŒ¨)")
        return pd.DataFrame()

    try:
        # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
        gc = gspread.service_account(filename='credentials.json')
        sh = gc.open("KBë¶€ë™ì‚°")
        worksheet = sh.worksheet('ì§€ì—­ë§µí•‘')
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = get_as_dataframe(worksheet, usecols=range(10)).dropna(axis=0, how='all')
        df = df[df['ì§€ì—­'].notna()] # Keyê°€ ì—†ëŠ” í–‰ ì œê±°
        
        # [ìˆ˜ì •] ë°ì´í„°ê°€ ì™„ë²½í•˜ë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ ë³„ë„ ì¤‘ë³µ ì œê±° ë¡œì§ ì‚­ì œ

        # Supabase ì—…ë¡œë“œìš© ë¦¬ìŠ¤íŠ¸ ìƒì„±
        records = []
        for _, row in df.iterrows():
            # NaN(ë¹ˆê°’)ì„ None(NULL)ìœ¼ë¡œ ë³€í™˜
            row = row.where(pd.notnull(row), None)
            
            record = {
                "kb_region_id": str(row['ì§€ì—­']),
                "division_1": row['ì§€ì—­êµ¬ë¶„1'],
                "division_2": row['ì§€ì—­êµ¬ë¶„2'],
                "division_3": row['ì§€ì—­êµ¬ë¶„3'],
                "display_name": row['ì§€ì—­ëª…'],
                "view_nation": row['ì „êµ­ë·°'],
                "view_capital": row['ìˆ˜ë„ê¶Œë·°'],
                "view_individual": row['ê°œë³„ë·°'],
                "view_group_name": row['ê°œë³„ë·°ìƒì„¸'],
                "view_order": row['ê°œë³„ë·°ë‚´ìˆœì„œ']
            }
            records.append(record)
            
        # [ì „ì²´ ë™ê¸°í™” í•µì‹¬] upsertë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì‹œíŠ¸ì˜ ì „ì²´ ë°ì´í„°ë¥¼ DBì— ë°˜ì˜í•©ë‹ˆë‹¤.
        # - ì´ë¯¸ ìˆëŠ” ì§€ì—­(Key) -> ì •ë³´ ì—…ë°ì´íŠ¸ (ì˜ˆ: ê·¸ë£¹ëª… ë³€ê²½ ë°˜ì˜)
        # - ì—†ëŠ” ì§€ì—­ -> ì‹ ê·œ ì¶”ê°€
        supabase.table("region_mapping").upsert(records).execute()
        print(f"âœ… ë§¤í•‘ í…Œì´ë¸” ë™ê¸°í™” ì™„ë£Œ ({len(records)}ê°œ ì§€ì—­)")
        
        return df.set_index('ì§€ì—­')
        
    except Exception as e:
        print(f"âŒ ë§¤í•‘ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# -----------------------------------------------------------
# [Step 2] KB ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±
# -----------------------------------------------------------
def download_kb_excel():
    print("\n[Step 2] KB ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    end_date = datetime.today().strftime('%Y-%m-%d')
    params_ref = {
        'ì£¼ì›”ê°„êµ¬ë¶„': '0',
        'ê¸°ì¤€ë…„ì›”ì‹œì‘ì¼': '2008-01-01',
        'ê¸°ì¤€ë…„ì›”ì¢…ë£Œì¼': end_date
    }
    
    try:
        url_ref = 'https://api.kbland.kr/land-extra/statistics/reference?' + urllib.parse.urlencode(params_ref)
        res = requests.get(url_ref, headers=headers)
        data = res.json()
        
        if not data['dataBody']['data']['ì‹œê³„ì—´']:
            return None
            
        filename = data['dataBody']['data']['ì‹œê³„ì—´'][0]['íŒŒì¼ëª…']
        filename_kor = data['dataBody']['data']['ì‹œê³„ì—´'][0]['ì›ë³¸íŒŒì¼ëª…']
        print(f"   íƒ€ê²Ÿ íŒŒì¼ëª…: {filename_kor}")
        
        params_file = {
            'urlpath': f'/kbstar/land/statc/tmsr/weekly/{filename}',
            'filename': filename_kor,
        }
        url_down = 'https://api.kbland.kr/land-extra/statistics/getfiledown'
        resp = requests.get(url_down, params=params_file, headers=headers)
        return pd.ExcelFile(BytesIO(resp.content))
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def process_sheet(excel, sheet_name, value_col_name, **kwargs):
    try:
        df = excel.parse(sheet_name, **kwargs)
    except:
        return pd.DataFrame()

    # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
    if 'êµ¬ë¶„' in df.columns:
        df = df.rename(columns={'êµ¬ë¶„': 'date'})
    elif len(df.columns) > 0:
        df.columns.values[0] = 'date'
        df = df.rename(columns={df.columns[0]: 'date'})

    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df = df.dropna(subset=['date'])

    # Wide -> Long ë³€í™˜
    df_melted = df.melt(id_vars=['date'], var_name='kb_region_id', value_name=value_col_name)
    df_melted[value_col_name] = pd.to_numeric(df_melted[value_col_name], errors='coerce')
    
    return df_melted

def clean_kb_data(df):
    # ì˜¤íƒ€ ìˆ˜ì •
    replacements = {'ê°•ì›íŠ¹ë³„ìì¹˜ë„ë„': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„'}
    df['kb_region_id'] = df['kb_region_id'].replace(replacements)
    df['kb_region_id'] = df['kb_region_id'].str.strip()
    return df

# -----------------------------------------------------------
# [Step 3] Supabase ì ì¬ ë¡œì§ (ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ & ì¦ë¶„ ì—…ë°ì´íŠ¸)
# -----------------------------------------------------------
def get_latest_date_from_db():
    """DBì—ì„œ ê°€ì¥ ìµœê·¼ ë°ì´í„° ë‚ ì§œë¥¼ ì¡°íšŒ"""
    try:
        response = supabase.table('real_estate_stats') \
            .select('date') \
            .order('date', desc=True) \
            .limit(1) \
            .execute()
        
        if response.data and len(response.data) > 0:
            return response.data[0]['date']
    except Exception as e:
        print(f"âš ï¸ ìµœì‹  ë‚ ì§œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    return None

def upload_stats_to_supabase(df):
    print(f"\n[Step 3] Supabase ì—…ë¡œë“œ ì‹œì‘ (ëŒ€ìƒ: {len(df)}í–‰)...")
    
    # 1000ê°œì”© ëŠì–´ì„œ ì—…ë¡œë“œ (Batch Insert)
    records = []
    for _, row in df.iterrows():
        record = {
            "date": row['date'].strftime('%Y-%m-%d'),
            "kb_region_id": str(row['kb_region_id']),
            "sale_index": row['sale_index'],
            "jeonse_index": row['jeonse_index'],
            "sale_change": row['sale_change'],
            "jeonse_change": row['jeonse_change']
        }
        # NaN ì²˜ë¦¬
        for k, v in record.items():
            if pd.isna(v): record[k] = None
        records.append(record)

    batch_size = 1000
    total_batches = (len(records) + batch_size - 1) // batch_size
    
    for i in range(0, len(records), batch_size):
        batch = records[i:i + batch_size]
        try:
            # ğŸš¨ [ì¦ë¶„ ì—…ë°ì´íŠ¸ í•µì‹¬] on_conflict ì‚¬ìš©
            # ë‚ ì§œì™€ ì§€ì—­ì´ ê²¹ì¹˜ë©´ ì—ëŸ¬ ëŒ€ì‹  Updateë¥¼ ìˆ˜í–‰í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
            supabase.table("real_estate_stats").upsert(
                batch, 
                on_conflict="date, kb_region_id"
            ).execute()
            print(f"   Uploading batch {i//batch_size + 1}/{total_batches} ... OK")
        except Exception as e:
            print(f"âŒ Batch {i//batch_size + 1} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# -----------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------------------------------------
def main():
    # 1. ë§¤í•‘ í…Œì´ë¸” ë™ê¸°í™” (ì „ì²´ ë™ê¸°í™” ìˆ˜í–‰)
    df_mapping = sync_region_mapping()
    if df_mapping.empty:
        print("âŒ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    # 2. ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
    excel_file = download_kb_excel()
    if not excel_file: return

    # 3. ë°ì´í„° íŒŒì‹±
    print("   ë°ì´í„° ê°€ê³µ ì¤‘...")
    df_sale_idx = process_sheet(excel_file, '3.ë§¤ë§¤ì§€ìˆ˜', 'sale_index', skiprows=[0, 2], header=[0])
    df_jeonse_idx = process_sheet(excel_file, '4.ì „ì„¸ì§€ìˆ˜', 'jeonse_index', skiprows=[0, 2], header=[0])
    df_sale_chg = process_sheet(excel_file, '1.ë§¤ë§¤ì¦ê°', 'sale_change', skiprows=[0, 2], skipfooter=9, header=[0])
    df_jeonse_chg = process_sheet(excel_file, '2.ì „ì„¸ì¦ê°', 'jeonse_change', skiprows=[0, 2], header=[0])

    dfs = [df_sale_idx, df_jeonse_idx, df_sale_chg, df_jeonse_chg]
    df_final = reduce(lambda left, right: pd.merge(left, right, on=['date', 'kb_region_id'], how='outer'), dfs)
    
    # ë°ì´í„° ì •ì œ (ì´ë¦„ í†µì¼)
    df_final = clean_kb_data(df_final)

    # ğŸš¨ [ì¤‘ìš”] KB ë°ì´í„° ìì²´ ì¤‘ë³µ í†µí•© (ì˜¤íƒ€ ë“±ìœ¼ë¡œ ì¸í•œ ì¤‘ë³µ í–‰ í•©ì¹˜ê¸°)
    print("   ì¤‘ë³µ ë°ì´í„° ë³‘í•© ì¤‘...")
    df_final = df_final.groupby(['date', 'kb_region_id'], as_index=False).max()

    # 4. ë‚ ì§œ í•„í„°ë§ (Python ë ˆë²¨ í•„í„°ë§)
    # DBì— ì´ë¯¸ ìˆëŠ” ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  'ìƒˆë¡œìš´ ë‚ ì§œ' ë°ì´í„°ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    last_db_date_str = get_latest_date_from_db()
    
    if last_db_date_str:
        print(f"\nğŸ” DB ìµœì‹  ë°ì´í„° ë‚ ì§œ: {last_db_date_str}")
        last_date = pd.to_datetime(last_db_date_str)
        
        # DB ë‚ ì§œë³´ë‹¤ 'ë¯¸ë˜'ì¸ ë°ì´í„°ë§Œ í•„í„°ë§
        original_count = len(df_final)
        df_final = df_final[df_final['date'] > last_date]
        
        print(f"   -> ì—…ë°ì´íŠ¸ ëŒ€ìƒ: {len(df_final)}í–‰ (ì „ì²´ {original_count}í–‰ ì¤‘)")
    else:
        print("\nğŸ” Full Load: DBê°€ ë¹„ì–´ìˆìœ¼ë¯€ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ì ì¬í•©ë‹ˆë‹¤.")

    if df_final.empty:
        print("âœ… ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
        return

    # 5. ë§¤í•‘ëœ ì§€ì—­ë§Œ ì¶”ì¶œ (Inner Join)
    df_upload_target = pd.merge(
        left=df_final,
        right=df_mapping,
        left_on='kb_region_id',
        right_index=True,
        how='inner'
    )
    
    # 6. ì—…ë¡œë“œ ì‹¤í–‰
    if not df_upload_target.empty:
        upload_stats_to_supabase(df_upload_target)
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸ ë§¤í•‘ í…Œì´ë¸”ê³¼ ì¼ì¹˜í•˜ëŠ” ì§€ì—­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()